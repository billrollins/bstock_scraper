
==================================================
File Path: E:/bstock_scraper/.env
==================================================
# B-Stock Credentials
BSTOCK_EMAIL=bill_rollins.rf@outlook.com
BSTOCK_PASSWORD=9$J8iCVr4Gi7pu2
# Update your .env file with the correct values
DB_HOST=localhost
DB_PORT=5432
DB_NAME=bstock_scraper
DB_USER=bstock_scraper
DB_PASSWORD=bstock_scraper
# Install required packages if not already installed
pip install psycopg2-binary python-dotenv alembic
# Initialize alembic (skip if already done)
alembic init alembic
# Create and run the migration
alembic revision --autogenerate -m "Initial migration"
alembic upgrade head

==================================================
File Path: E:/bstock_scraper/.env.example
==================================================
Environment Files
# .env.example
# B-Stock Credentials
BSTOCK_EMAIL=your_email@example.com
BSTOCK_PASSWORD=your_password
# PostgreSQL Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=bstock_scraper
DB_USER=your_db_username
DB_PASSWORD=your_db_password
# Scraping Configuration
REQUESTS_PER_MINUTE=60
CONCURRENT_REQUESTS=5

==================================================
File Path: E:/bstock_scraper/.gitignore
==================================================
venv/
__pycache__/
*.pyc
.env
.pytest_cache/
.coverage
.vscode/
.idea/

==================================================
File Path: E:/bstock_scraper/alembic.ini
==================================================
[alembic]
script_location = alembic
# This will be overridden by env.py
sqlalchemy.url = driver://user:pass@localhost/dbname
[loggers]
keys = root,sqlalchemy,alembic
[handlers]
keys = console
[formatters]
keys = generic
[logger_root]
level = WARN
handlers = console
qualname =
[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine
[logger_alembic]
level = INFO
handlers =
qualname = alembic
[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic
[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S

==================================================
File Path: E:/bstock_scraper/README.md
==================================================
# B-Stock Scraper
A Python-based web scraper for collecting auction data from B-Stock marketplaces (Amazon and Target). The scraper monitors auctions, tracks pricing, and stores historical data for analysis.
## Project Structure
```
bstock_scraper/
├── alembic/              # Database migrations
├── config/
│   ├── settings.py       # Application configuration
│   └── marketplaces/     # Marketplace-specific settings
├── notebooks/            # Jupyter notebooks for data analysis
├── scripts/
│   ├── export_data.py    # Data export utilities
│   └── run_scraper.py    # Main execution script
├── src/
│   ├── core/             # Core functionality
│   │   ├── auth.py       # Authentication handling
│   │   ├── rate_limiter.py  # Request rate limiting
│   │   └── scraper.py    # Main scraping logic
│   ├── models/           # Data models
│   │   ├── auction.py    # Auction data structure
│   │   └── marketplace.py # Marketplace configuration
│   ├── parsers/          # HTML parsing
│   │   ├── amazon_parser.py
│   │   ├── base_parser.py
│   │   └── target_parser.py
│   ├── storage/          # Data persistence
│   │   ├── database.py   # Database operations
│   │   └── exporters.py  # Export functionality
│   └── utils/            # Utility functions
│       ├── http.py       # HTTP helpers
│       └── logging.py    # Logging configuration
└── tests/                # Test suite
```
## Features
- Scrapes auction data from multiple B-Stock marketplaces:
- Amazon Returns
- Target Liquidation
- Implements rate limiting to respect website policies
- Stores data in PostgreSQL database
- Tracks key auction metrics:
- Current bid
- Total units
- Retail value
- Location
- Shipping costs
- Cost per unit
- Auction end time
## Setup
1. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # Unix
.\venv\Scripts\activate   # Windows
```
2. Install dependencies:
```bash
pip install -r requirements.txt
```
3. Copy `.env.example` to `.env` and update with your credentials:
```bash
cp .env.example .env
```
4. Initialize the database:
```bash
alembic upgrade head
```
## TODOs
### High Priority
- [ ] Implement authentication in `src/core/auth.py`
- [ ] Complete Amazon parser implementation in `src/parsers/amazon_parser.py`
- [ ] Implement Target parser in `src/parsers/target_parser.py`
- [ ] Add error handling and retry logic in `src/core/scraper.py`
- [ ] Implement main scraping loop in `scripts/run_scraper.py`
### Medium Priority
- [ ] Add database models for historical price tracking
- [ ] Implement shipping cost calculator
- [ ] Add logging throughout the application
- [ ] Create data export functionality in `scripts/export_data.py`
- [ ] Add unit tests for parsers and data models
### Low Priority
- [ ] Add documentation for all modules
- [ ] Create dashboard for visualizing auction data
- [ ] Implement email notifications for interesting auctions
- [ ] Add support for additional B-Stock marketplaces
- [ ] Create Dockerfile for containerization
### Infrastructure
- [ ] Set up CI/CD pipeline
- [ ] Add monitoring and alerting
- [ ] Implement backup strategy for database
- [ ] Add rate limiting configuration per marketplace
- [ ] Create deployment documentation
## Contributing
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request
## License
This project is private and confidential.
## Notes
- Remember to respect B-Stock's terms of service and rate limiting
- Keep credentials secure and never commit them to the repository
- Regular backups of the database are recommended

==================================================
File Path: E:/bstock_scraper/requirements.txt
==================================================
aiohappyeyeballs==2.4.3
aiohttp==3.10.10
aiosignal==1.3.1
alembic==1.13.3
annotated-types==0.7.0
asttokens==2.4.1
attrs==24.2.0
beautifulsoup4==4.12.3
bs4==0.0.2
certifi==2024.8.30
chardet==5.2.0
charset-normalizer==3.4.0
colorama==0.4.6
comm==0.2.2
debugpy==1.8.7
decorator==5.1.1
executing==2.1.0
frozenlist==1.5.0
greenlet==3.1.1
idna==3.10
iniconfig==2.0.0
ipykernel==6.29.5
ipython==8.29.0
jedi==0.19.1
jupyter_client==8.6.3
jupyter_core==5.7.2
Mako==1.3.6
MarkupSafe==3.0.2
matplotlib-inline==0.1.7
multidict==6.1.0
nest-asyncio==1.6.0
numpy==2.1.3
packaging==24.1
pandas==2.2.3
parso==0.8.4
platformdirs==4.3.6
pluggy==1.5.0
prompt_toolkit==3.0.48
propcache==0.2.0
psutil==6.1.0
psycopg2-binary==2.9.10
pure_eval==0.2.3
pydantic==2.9.2
pydantic_core==2.23.4
Pygments==2.18.0
pytest==8.3.3
pytest-asyncio==0.24.0
python-dateutil==2.9.0.post0
python-dotenv==1.0.1
pytz==2024.2
pywin32==308
pyzmq==26.2.0
requests==2.32.3
six==1.16.0
soupsieve==2.6
SQLAlchemy==2.0.36
stack-data==0.6.3
tornado==6.4.1
traitlets==5.14.3
typing_extensions==4.12.2
tzdata==2024.2
urllib3==2.2.3
wcwidth==0.2.13
yarl==1.17.1


==================================================
File Path: E:/bstock_scraper/config/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/config/settings.py
==================================================
from pydantic_settings import BaseSettings
from typing import Optional
from functools import lru_cache
class Settings(BaseSettings):
# Database settings
DB_HOST: str
DB_PORT: str
DB_NAME: str
DB_USER: str
DB_PASSWORD: str
DATABASE_URL: Optional[str] = None
# B-Stock credentials
BSTOCK_EMAIL: str
BSTOCK_PASSWORD: str
# Scraping settings
REQUESTS_PER_MINUTE: int = 60
CONCURRENT_REQUESTS: int = 5
# Base URLs
AMAZON_BASE_URL: str = "https://bstock.com/amazon"
TARGET_BASE_URL: str = "https://bstock.com/target"
class Config:
env_file = ".env"
def __init__(self, **kwargs):
super().__init__(**kwargs)
if not self.DATABASE_URL:
self.DATABASE_URL = f"postgresql://{self.DB_USER}:{self.DB_PASSWORD}@{self.DB_HOST}:{self.DB_PORT}/{self.DB_NAME}"
@lru_cache()
def get_settings() -> Settings:
return Settings()

==================================================
File Path: E:/bstock_scraper/config/marketplaces/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/config/marketplaces/amazon.py
==================================================
# Amazon-specific settings

==================================================
File Path: E:/bstock_scraper/config/marketplaces/target.py
==================================================
# Target-specific settings

==================================================
File Path: E:/bstock_scraper/notebooks/database_notebook.ipynb
==================================================
{
"cells": [
{
"cell_type": "markdown",
"metadata": {},
"source": [
"# Database Exploration\n",
"\n",
"This notebook helps explore and verify our database structure."
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Add the project root to Python path so we can import our modules\n",
"import sys\n",
"from pathlib import Path\n",
"project_root = str(Path.cwd().parent)\n",
"if project_root not in sys.path:\n",
"    sys.path.append(project_root)\n",
"\n",
"# Import required modules\n",
"from sqlalchemy import inspect\n",
"from src.storage.database import engine\n",
"\n",
"# Setup prettier display for DataFrames if we need them later\n",
"import pandas as pd\n",
"pd.set_option('display.max_columns', None)\n",
"pd.set_option('display.max_rows', 50)"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Inspect database structure\n",
"inspector = inspect(engine)\n",
"\n",
"# Get all tables\n",
"for table_name in inspector.get_table_names():\n",
"    print(f\"\\nTable: {table_name}\")\n",
"    \n",
"    # Get columns\n",
"    print(\"Columns:\")\n",
"    for column in inspector.get_columns(table_name):\n",
"        print(f\"  - {column['name']}: {column['type']}\")\n",
"    \n",
"    # Get indexes\n",
"    print(\"\\nIndexes:\")\n",
"    for index in inspector.get_indexes(table_name):\n",
"        print(f\"  - {index['name']}: {index['column_names']}\")\n",
"    \n",
"    # Get foreign keys\n",
"    print(\"\\nForeign Keys:\")\n",
"    for fk in inspector.get_foreign_keys(table_name):\n",
"        print(f\"  - {fk['name']}: {fk['referred_table']}\")"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# Helper function to query tables\n",
"def get_table_data(table_name, limit=5):\n",
"    \"\"\"Get sample data from a table\"\"\"\n",
"    query = f\"SELECT * FROM {table_name} LIMIT {limit}\"\n",
"    return pd.read_sql(query, engine)\n",
"\n",
"# Example usage:\n",
"# df = get_table_data('auctions')\n",
"# df"
]
}
],
"metadata": {
"kernelspec": {
"display_name": "venv",
"language": "python",
"name": "python3"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.12.0"
}
},
"nbformat": 4,
"nbformat_minor": 2
}

==================================================
File Path: E:/bstock_scraper/prompts/HTML amazon all-inventory.html
==================================================
<!-- https://bstock.com/amazon/ -->
<ul class="products-grid products-grid--max-4-col">
<li id="auction-26964">
<a
href="https://bstock.com/amazon/auction/auction/view/id/26964/"
class="product-image product-image-amz_ov_20241031_006"
>
<img
alt="Auction Image"
src="https://storage.googleapis.com/bfile-prod-assets-img/amz/auto_category/gl_Apparel-small.png"
style=""
/></a>
<div class="product-info" style="min-height: 226px">
<div class="product-name">
<a href="https://bstock.com/amazon/auction/auction/view/id/26964/"
>Est. 2 Pallets of Apparel &amp; More, 974 Units, Used - Good
Condition, Ext. Retail $44,826, North Las Vegas, NV - West Coast
</a>
</div>
<div class="current_bid" id="current_bid_amt26964">
<span class="label">Current bid:</span>
<span class="price"><strong>$2,202</strong></span>
</div>
<div class="cost_per_unit">
<span class="label">Avg. Cost Per Unit: </span>
<span class="price">
<strong> $2.26 </strong>
</span>
</div>
<div class="bids_number">
<span class="label">Bids: </span
><strong><span id="bid_number26964">23</span></strong>
</div>
<div class="time_remaining">
<span class="label"> Closes in </span>
<strong>
<span
id="auction_time_remaining26964"
class="countdown ending-soon"
data-auction-id="26964"
data-end-time="Sat, 02 Nov 2024 14:48:00 -0700"
>1m 5s</span
>
</strong>
</div>
...
</div>
</li>
...
</ul>

==================================================
File Path: E:/bstock_scraper/prompts/HTML amazon auction detail.html
==================================================
<!-- https://bstock.com/amazon/auction/auction/view/id/27096/ -->
<div class="product-essential">
<!-- Auction Title -->
<div class="product-name">
<h1>Est. 2 Pallets of Outdoors by Speedo, Retrospec, Bell &amp; More, 981 Units, Used - Good Condition, Ext. Retail $19,051, North Las Vegas, NV - West Coast</h1>
</div>
<!-- Bid Information -->
<div class="auction-data-row">
<div id="current_bid_label">Current bid</div>
<div class="auction-data-content">
<span id="current_bid_amount">$600</span>
</div>
<span class="auction-actions">
<span id="bid_number">13</span>
<span id="bid_history_label_plural">Bids</span>
</span>
</div>
<!-- Next Minimum Bid -->
<div class="auction-data-row">
<span id="next_current_bid" class="price">$625</span>
</div>
<!-- Shipping Information -->
<div class="auction-data-row">
<div class="auction-data-label">Shipping Cost</div>
<div id="shipping_total_cost">
<span class="price">$262.68</span>
</div>
<div class="softcheckout-address">
<address id="softcheckout-display-address">
<span>8052 H ST, OMAHA, Nebraska 68127-1716</span>
</address>
</div>
</div>
<!-- Per Unit Cost -->
<div class="auction-data-row">
<div class="auction-data-label">Avg. Cost Per Unit</div>
<div id="auction_cost_per_unit">
<span id="unit_per_price_span" class="price">$0.61</span>
</div>
</div>
<!-- Auction End Time -->
<div class="auction-data-row">
<div class="auction-data-label">Closes in</div>
<div class="auction-data-content">
<span id="auction_time_remaining" class="ending-soon">1m 16s</span>
</div>
</div>
<!-- Close Date -->
<div class="auction-data-row">
<div class="auction-data-label">Close Date</div>
<div class="auction-data-content">
<span id="auction_end_time">Sat Nov 2, 2024 5:06:00 PM</span>
<span class="tz_abbr">CDT</span>
</div>
</div>
</div>

==================================================
File Path: E:/bstock_scraper/prompts/HTML target all-inventory.html
==================================================
<!-- https://bstock.com/target/ -->
<ul class="products-grid products-grid--max-4-col">
<li id="auction-119203">
<a
href="https://bstock.com/target/auction/auction/view/id/119203/"
class="product-image product-image-urc_womens_apparel_2_20241031_145_p"
>
<img
alt="Auction Image"
src="https://storage.googleapis.com/bfile-prod-assets-img/tgt/category/67-small.png"
style=""
/></a>
<div class="product-info" style="min-height: 205px">
<div class="product-name">
<a href="https://bstock.com/target/auction/auction/view/id/119203/"
>1 Pallet of Women's Apparel &amp; Accessories by Levi's &amp; More,
Used - Good Condition, 1,085 Units, Ext. Retail $24,050, Upper
Marlboro, MD
</a>
</div>
<div class="current_bid" id="current_bid_amt119203">
<span class="label">Current bid:</span>
<span class="price"><strong>$100</strong></span>
</div>
<div class="cost_per_unit">
<span class="label">Avg. Cost Per Unit: </span>
<span class="price">
<strong> $0.09 </strong>
</span>
</div>
<div class="bids_number">
<span class="label">Bids: </span
><strong><span id="bid_number119203">0</span></strong>
</div>
<div class="time_remaining">
<span class="label"> Closes in </span>
<strong>
<span
id="auction_time_remaining119203"
class="countdown"
data-auction-id="119203"
data-end-time="Sun, 03 Nov 2024 13:00:00 -0600"
>21h 21m</span
>
</strong>
</div>
</div>
</li>
...
</ul>

==================================================
File Path: E:/bstock_scraper/prompts/HTML target auction detail.html
==================================================
<!-- https://bstock.com/target/auction/auction/view/id/119203/ -->
<div class="product-essential">
<!-- Auction Title -->
<div class="product-name">
<h1>
1 Pallet of Women's Apparel &amp; Accessories by Levi's &amp; More, Used -
Good Condition, 1,085 Units, Ext. Retail $24,050, Upper Marlboro, MD
</h1>
</div>
<!-- Bid Information -->
<div class="auction-data-row">
<div id="current_bid_label" class="auction-data-label">Opening bid</div>
<div class="auction-data-content">
<span id="current_bid_amount">$100</span>
</div>
<span class="auction-actions">
<span id="bid_number">0</span>
<span id="bid_history_label_plural">Bids</span>
</span>
</div>
<!-- Additional Fees -->
<div class="auction-data-row">
<div class="auction-data-label">Additional Charges</div>
<div class="auction-data-content">
<span id="buyersPremiumLabelResult">$4.00</span> B-Stock Fee
</div>
</div>
<!-- Shipping Information -->
<div class="auction-data-row">
<div class="auction-data-label">Shipping Cost</div>
<div id="shipping_total_cost">
<span class="price">$370.66</span>
</div>
<!-- Shipping Details -->
<div id="shipping_info">
<div id="auction_origin">Upper Marlboro, MD, 20774</div>
<div id="quote_address_string">8052 H ST, OMAHA, Nebraska 68127-1716</div>
<!-- Additional shipping details -->
<div>Weight: 573.0000 lb.</div>
<div># of pallets: 1</div>
<div>Pallet spaces: 1</div>
</div>
</div>
<!-- Per Unit Cost -->
<div class="auction-data-row">
<div class="auction-data-label">Avg. Cost Per Unit</div>
<div id="auction_cost_per_unit">
<span id="unit_per_price_span" class="price">$0.09</span>
</div>
</div>
<!-- Auction End Time -->
<div class="auction-data-row">
<div class="auction-data-label">Closes in</div>
<div class="auction-data-content">
<span id="auction_time_remaining">21h 2m</span>
</div>
</div>
<!-- Close Date -->
<div class="auction-data-row">
<div class="auction-data-label">Close Date</div>
<div class="auction-data-content">
<span id="auction_end_time">Sun Nov 3, 2024 1:00:00 PM</span>
<span class="tz_abbr">CST</span>
</div>
</div>
</div>

==================================================
File Path: E:/bstock_scraper/scripts/export_data.py
==================================================
# Data export script

==================================================
File Path: E:/bstock_scraper/scripts/run_scraper.py
==================================================
# Main script

==================================================
File Path: E:/bstock_scraper/src/core/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/src/core/auth.py
==================================================
import logging
import aiohttp
from typing import Optional
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
from ..utils.http import get_user_agent
logger = logging.getLogger(__name__)
class AuthenticationError(Exception):
"""Raised when authentication fails"""
pass
class BStockAuthenticator:
"""Handles authentication with B-Stock marketplaces"""
def __init__(self, email: str, password: str, marketplace: str = "amazon"):
"""
Initialize authenticator with credentials
Args:
email: B-Stock account email
password: B-Stock account password
marketplace: Which marketplace to authenticate with ("amazon" or "target")
"""
self.email = email
self.password = password
self.marketplace = marketplace.lower()
self.session: Optional[aiohttp.ClientSession] = None
self.last_auth: Optional[datetime] = None
self.auth_token: Optional[str] = None
# Define marketplace-specific URLs
self.base_urls = {
"amazon": "https://bstock.com/amazon",
"target": "https://bstock.com/target"
}
if self.marketplace not in self.base_urls:
raise ValueError(f"Unsupported marketplace: {marketplace}")
self.base_url = self.base_urls[marketplace]
async def __aenter__(self):
"""Async context manager entry"""
await self.login()
return self
async def __aexit__(self, exc_type, exc_val, exc_tb):
"""Async context manager exit"""
await self.close()
async def create_session(self) -> None:
"""Create a new aiohttp session with appropriate headers"""
if self.session:
await self.session.close()
headers = {
"User-Agent": get_user_agent(),
"Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
"Accept-Language": "en-US,en;q=0.5",
"Accept-Encoding": "gzip, deflate, br",
"DNT": "1",
"Connection": "keep-alive",
"Upgrade-Insecure-Requests": "1"
}
self.session = aiohttp.ClientSession(headers=headers)
async def close(self) -> None:
"""Close the session"""
if self.session:
await self.session.close()
self.session = None
def is_authenticated(self) -> bool:
"""Check if current session is authenticated and not expired"""
if not self.last_auth or not self.session:
return False
# Check if authentication is older than 1 hour
auth_age = datetime.now() - self.last_auth
return auth_age < timedelta(hours=1)
async def login(self) -> None:
"""Authenticate with B-Stock and establish a session"""
if not self.session:
await self.create_session()
# Check if we have a valid session
if self.is_authenticated():
return
try:
# First get the login page to obtain CSRF token
response = await self.session.get(f"{self.base_url}/customer/account/login/")
await response.raise_for_status()
html = await response.text()
soup = BeautifulSoup(html, 'html.parser')
form_key = soup.select_one('input[name="form_key"]')
if not form_key:
raise AuthenticationError("Could not find form key in login page")
form_key = form_key['value']
# Prepare login data
login_data = {
'form_key': form_key,
'login[username]': self.email,
'login[password]': self.password,
'send': ''
}
# Perform login
login_url = f"{self.base_url}/customer/account/loginPost/"
response = await self.session.post(login_url, data=login_data, allow_redirects=True)
await response.raise_for_status()
# Check if login was successful
if "customer/account/login" in str(response.url):
raise AuthenticationError("Login failed - Invalid credentials")
# Store authentication time
self.last_auth = datetime.now()
# Extract authentication token from cookies if available
self.auth_token = response.cookies.get('frontend')  # Adjust cookie name if needed
except aiohttp.ClientError as e:
raise AuthenticationError(f"Login failed - Network error: {str(e)}")
except Exception as e:
raise AuthenticationError(f"Login failed - Unexpected error: {str(e)}")
async def make_authenticated_request(self, url: str, method: str = "GET", **kwargs) -> aiohttp.ClientResponse:
"""Make an authenticated request to B-Stock"""
if not self.is_authenticated():
await self.login()
try:
response = await self.session.request(method, url, **kwargs)
await response.raise_for_status()
return response
except aiohttp.ClientError as e:
if response.status == 401:
# Try to re-authenticate once
await self.login()
response = await self.session.request(method, url, **kwargs)
await response.raise_for_status()
return response
raise AuthenticationError(f"Request failed: {str(e)}")

==================================================
File Path: E:/bstock_scraper/src/core/rate_limiter.py
==================================================
# Rate limiting implementation
import time
from datetime import datetime, timedelta
from collections import deque
from typing import Deque, Optional
import logging
logger = logging.getLogger(__name__)
class RateLimiter:
"""Rate limiter implementation using token bucket algorithm"""
def __init__(self, requests_per_minute: int = 60):
self.requests_per_minute = requests_per_minute
self.window_size = 60  # 1 minute in seconds
self.requests: Deque[datetime] = deque()
async def acquire(self) -> bool:
"""Acquire permission to make a request"""
now = datetime.now()
# Remove requests older than window_size
while self.requests and (now - self.requests[0]).total_seconds() > self.window_size:
self.requests.popleft()
# Check if we can make a new request
if len(self.requests) < self.requests_per_minute:
self.requests.append(now)
return True
# Calculate wait time
wait_time = (self.requests[0] + timedelta(seconds=self.window_size) - now).total_seconds()
if wait_time > 0:
logger.info(f"Rate limit reached, waiting {wait_time:.2f} seconds")
time.sleep(wait_time)
self.requests.popleft()
self.requests.append(datetime.now())
return True
return False

==================================================
File Path: E:/bstock_scraper/src/core/scraper.py
==================================================
# Core scraping functionality

==================================================
File Path: E:/bstock_scraper/src/models/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/src/models/auction.py
==================================================
# Auction data model
from dataclasses import dataclass
from datetime import datetime
from typing import Optional
@dataclass
class Auction:
"""Base auction model representing common fields across marketplaces"""
auction_id: str
title: str
current_bid: float
total_units: int
condition: str
retail_value: float
location: str
end_time: datetime
shipping_cost: Optional[float] = None
total_bids: Optional[int] = None
cost_per_unit: Optional[float] = None
marketplace: str
source_url: str
@property
def is_ending_soon(self) -> bool:
"""Check if auction is ending within 1 hour"""
if not self.end_time:
return False
return (self.end_time - datetime.now()).total_seconds() < 3600

==================================================
File Path: E:/bstock_scraper/src/models/marketplace.py
==================================================
# Marketplace configuration model

==================================================
File Path: E:/bstock_scraper/src/models/shipping.py
==================================================
# Shipping details model

==================================================
File Path: E:/bstock_scraper/src/parsers/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/src/parsers/amazon_parser.py
==================================================
# Amazon marketplace parser
from typing import List, Optional
from bs4 import BeautifulSoup
from datetime import datetime
from .base_parser import BaseParser
from ..models.auction import Auction
class AmazonParser(BaseParser):
"""Parser implementation for Amazon B-Stock marketplace"""
def parse_auction_list(self, html: str) -> List[Auction]:
soup = BeautifulSoup(html, 'html.parser')
auctions = []
for item in soup.select('li[id^="auction-"]'):
try:
auction_id = item['id'].replace('auction-', '')
title = item.select_one('.product-name a').text.strip()
current_bid = self._parse_price(item.select_one('.current_bid .price strong').text)
cost_per_unit = self._parse_price(item.select_one('.cost_per_unit .price strong').text)
total_bids = int(item.select_one('.bids_number strong span').text)
# Extract end time
end_time_elem = item.select_one('.time_remaining span[data-end-time]')
end_time = self._parse_datetime(end_time_elem['data-end-time']) if end_time_elem else None
# Create auction object
auction = Auction(
auction_id=auction_id,
title=title,
current_bid=current_bid,
total_units=0,  # Will be updated from detail page
condition="",   # Will be updated from detail page
retail_value=0, # Will be updated from detail page
location="",    # Will be updated from detail page
end_time=end_time,
total_bids=total_bids,
cost_per_unit=cost_per_unit,
marketplace="amazon",
source_url=f"https://bstock.com/amazon/auction/auction/view/id/{auction_id}/"
)
auctions.append(auction)
except Exception as e:
logger.error(f"Error parsing auction {auction_id}: {str(e)}")
continue
return auctions
def parse_auction_detail(self, html: str) -> Optional[Auction]:
"""Parse Amazon auction detail page"""
soup = BeautifulSoup(html, 'html.parser')
try:
# Implementation of detail page parsing
pass
except Exception as e:
logger.error(f"Error parsing auction detail: {str(e)}")
return None

==================================================
File Path: E:/bstock_scraper/src/parsers/base_parser.py
==================================================
# Abstract base parser
from abc import ABC, abstractmethod
from typing import List, Optional
from bs4 import BeautifulSoup
from ..models.auction import Auction
class BaseParser(ABC):
"""Abstract base class for marketplace-specific parsers"""
@abstractmethod
def parse_auction_list(self, html: str) -> List[Auction]:
"""Parse auction listing page and return list of auctions"""
pass
@abstractmethod
def parse_auction_detail(self, html: str) -> Optional[Auction]:
"""Parse individual auction detail page"""
pass
def _parse_price(self, price_str: str) -> float:
"""Helper method to parse price strings"""
try:
return float(price_str.replace('$', '').replace(',', '').strip())
except (ValueError, AttributeError):
return 0.0
def _parse_datetime(self, date_str: str) -> Optional[datetime]:
"""Helper method to parse datetime strings"""
try:
return datetime.strptime(date_str.strip(), '%a %b %d, %Y %I:%M:%S %p')
except (ValueError, AttributeError):
return None

==================================================
File Path: E:/bstock_scraper/src/parsers/target_parser.py
==================================================
# Target marketplace parser

==================================================
File Path: E:/bstock_scraper/src/storage/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/src/storage/database.py
==================================================
# Database operations
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import QueuePool
import os
from dotenv import load_dotenv
load_dotenv()
# Database URL construction
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST", "localhost")
DB_PORT = os.getenv("DB_PORT", "5432")
DB_NAME = os.getenv("DB_NAME")
DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
# SQLAlchemy setup
engine = create_engine(
DATABASE_URL,
poolclass=QueuePool,
pool_size=5,
max_overflow=10,
pool_timeout=30,
pool_pre_ping=True
)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
Base = declarative_base()
# Dependency to get DB session
def get_db():
db = SessionLocal()
try:
yield db
finally:
db.close()
# src/models/database_models.py
from sqlalchemy import Column, Integer, String, Float, DateTime, ForeignKey
from sqlalchemy.orm import relationship
from ..storage.database import Base
from datetime import datetime
class AuctionDB(Base):
__tablename__ = "auctions"
id = Column(Integer, primary_key=True, index=True)
auction_id = Column(String, unique=True, index=True)
marketplace = Column(String, index=True)
title = Column(String)
current_bid = Column(Float)
total_units = Column(Integer)
condition = Column(String)
retail_value = Column(Float)
location = Column(String)
end_time = Column(DateTime)
shipping_cost = Column(Float, nullable=True)
total_bids = Column(Integer, nullable=True)
cost_per_unit = Column(Float, nullable=True)
source_url = Column(String)
created_at = Column(DateTime, default=datetime.utcnow)
updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

==================================================
File Path: E:/bstock_scraper/src/storage/exporters.py
==================================================
# Data export handlers

==================================================
File Path: E:/bstock_scraper/src/utils/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/src/utils/http.py
==================================================
# HTTP utilities
import random
from typing import List, Optional
from datetime import datetime
import logging
logger = logging.getLogger(__name__)
def get_user_agent() -> str:
"""
Returns a randomly selected user agent string from a list of common browsers.
This helps prevent blocking by making requests appear more like regular browser traffic.
"""
user_agents = [
# Chrome on Windows 10
"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
# Firefox on Windows 10
"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0",
# Edge on Windows 10
"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0",
# Safari on macOS
"Mozilla/5.0 (Macintosh; Intel Mac OS X 14_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
# Chrome on macOS
"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
]
return random.choice(user_agents)
class RequestError(Exception):
"""Base exception for HTTP request errors"""
pass
class HTTPClient:
"""
HTTP client utility class with built-in retry logic and error handling
"""
def __init__(self, max_retries: int = 3, timeout: int = 30):
self.max_retries = max_retries
self.timeout = timeout
self._session = None
self._last_request_time: Optional[datetime] = None
def get_headers(self, additional_headers: Optional[dict] = None) -> dict:
"""
Get default headers with optional additional headers
Args:
additional_headers: Optional dictionary of additional headers to include
Returns:
Dictionary of HTTP headers
"""
headers = {
"User-Agent": get_user_agent(),
"Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
"Accept-Language": "en-US,en;q=0.5",
"Accept-Encoding": "gzip, deflate, br",
"DNT": "1",
"Connection": "keep-alive",
"Upgrade-Insecure-Requests": "1",
"Sec-Fetch-Dest": "document",
"Sec-Fetch-Mode": "navigate",
"Sec-Fetch-Site": "none",
"Sec-Fetch-User": "?1",
"Cache-Control": "max-age=0"
}
if additional_headers:
headers.update(additional_headers)
return headers
@staticmethod
def parse_cookies(cookie_string: str) -> dict:
"""
Parse cookie string into dictionary
Args:
cookie_string: String containing cookies
Returns:
Dictionary of cookie name-value pairs
"""
cookies = {}
if not cookie_string:
return cookies
for cookie in cookie_string.split(';'):
if '=' in cookie:
name, value = cookie.split('=', 1)
cookies[name.strip()] = value.strip()
return cookies
@staticmethod
def build_url(base_url: str, path: str = "", params: Optional[dict] = None) -> str:
"""
Build complete URL from components
Args:
base_url: Base URL
path: Optional path to append
params: Optional query parameters
Returns:
Complete URL string
"""
url = base_url.rstrip('/')
if path:
url += '/' + path.lstrip('/')
if params:
param_strings = []
for key, value in params.items():
if isinstance(value, (list, tuple)):
for v in value:
param_strings.append(f"{key}={v}")
else:
param_strings.append(f"{key}={value}")
if param_strings:
url += '?' + '&'.join(param_strings)
return url
@staticmethod
def is_success_status(status_code: int) -> bool:
"""Check if HTTP status code indicates success"""
return 200 <= status_code < 300
@staticmethod
def should_retry(status_code: int) -> bool:
"""
Determine if request should be retried based on status code
Args:
status_code: HTTP status code
Returns:
Boolean indicating if retry is appropriate
"""
# Retry on server errors (5xx) and specific client errors
return (
status_code >= 500 or  # Server errors
status_code == 429 or  # Too Many Requests
status_code == 408 or  # Request Timeout
status_code == 404     # Not Found (temporary)
)

==================================================
File Path: E:/bstock_scraper/src/utils/logging.py
==================================================
# Logging configuration
import logging
import sys
from typing import Optional
def setup_logging(level: int = logging.INFO,
log_file: Optional[str] = None) -> None:
"""Configure logging for the application"""
# Create formatter
formatter = logging.Formatter(
'%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
# Setup console handler
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setFormatter(formatter)
# Setup root logger
root_logger = logging.getLogger()
root_logger.setLevel(level)
root_logger.addHandler(console_handler)
# Setup file handler if log file specified
if log_file:
file_handler = logging.FileHandler(log_file)
file_handler.setFormatter(formatter)
root_logger.addHandler(file_handler)

==================================================
File Path: E:/bstock_scraper/src/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/tests/__init__.py
==================================================


==================================================
File Path: E:/bstock_scraper/tests/test_auth.py
==================================================
import pytest
from unittest.mock import Mock, patch, AsyncMock
from datetime import datetime, timedelta
from aiohttp import ClientResponse, ClientSession
from bs4 import BeautifulSoup
from src.core.auth import BStockAuthenticator, AuthenticationError
# Test data
TEST_EMAIL = "test@example.com"
TEST_PASSWORD = "password123"
TEST_FORM_KEY = "testformkey123"
class MockResponse:
def __init__(self, status=200, url="", text="", cookies=None):
self.status = status
self.url = url
self._text = text
self.cookies = cookies or {}
async def raise_for_status(self):
if self.status >= 400:
raise Exception(f"HTTP Error {self.status}")
async def text(self):
return self._text
@pytest.fixture
def mock_response():
"""Create a mock response with login form"""
html = f'<html><input name="form_key" value="{TEST_FORM_KEY}"></html>'
return MockResponse(text=html)
@pytest.fixture
def mock_login_response():
"""Create a mock successful login response"""
return MockResponse(
url="https://bstock.com/amazon/customer/account/",
cookies={"frontend": "test_token"}
)
@pytest.fixture
def mock_session():
"""Create a mock session"""
mock = AsyncMock(spec=ClientSession)
async def mock_get(*args, **kwargs):
return mock_response()
async def mock_post(*args, **kwargs):
return mock_login_response()
mock.get = AsyncMock(side_effect=mock_get)
mock.post = AsyncMock(side_effect=mock_post)
mock.request = AsyncMock(side_effect=mock_get)
mock.close = AsyncMock()
return mock
@pytest.fixture
async def authenticator(mock_session):
"""Create an authenticator instance with mocked session"""
with patch('aiohttp.ClientSession', return_value=mock_session):
auth = BStockAuthenticator(TEST_EMAIL, TEST_PASSWORD)
yield auth
await auth.close()
@pytest.mark.asyncio
async def test_init():
"""Test authenticator initialization"""
auth = BStockAuthenticator(TEST_EMAIL, TEST_PASSWORD)
assert auth.email == TEST_EMAIL
assert auth.password == TEST_PASSWORD
assert auth.marketplace == "amazon"
assert auth.session is None
assert auth.last_auth is None
@pytest.mark.asyncio
async def test_init_invalid_marketplace():
"""Test initialization with invalid marketplace"""
with pytest.raises(ValueError):
BStockAuthenticator(TEST_EMAIL, TEST_PASSWORD, marketplace="invalid")
@pytest.mark.asyncio
async def test_create_session(authenticator):
"""Test session creation"""
await authenticator.create_session()
assert authenticator.session is not None
assert isinstance(authenticator.session, AsyncMock)
@pytest.mark.asyncio
async def test_login_success(authenticator, mock_session, mock_response, mock_login_response):
"""Test successful login"""
mock_session.get.return_value = mock_response
mock_session.post.return_value = mock_login_response
await authenticator.login()
# Verify login request was made
assert mock_session.post.called
call_args = mock_session.post.call_args
assert "loginPost" in call_args[0][0]
# Verify authentication state
assert authenticator.is_authenticated()
assert authenticator.auth_token == "test_token"
@pytest.mark.asyncio
async def test_login_failure(authenticator, mock_session):
"""Test failed login"""
# Mock a failed login response
failed_response = MockResponse(
url="https://bstock.com/amazon/customer/account/login/",
text=f'<html><input name="form_key" value="{TEST_FORM_KEY}"></html>'
)
mock_session.post.return_value = failed_response
with pytest.raises(AuthenticationError):
await authenticator.login()
@pytest.mark.asyncio
async def test_is_authenticated(authenticator):
"""Test authentication status checking"""
assert not authenticator.is_authenticated()
# Set up authenticated state
authenticator.last_auth = datetime.now()
authenticator.session = mock_session()
assert authenticator.is_authenticated()
# Test expired authentication
authenticator.last_auth = datetime.now() - timedelta(hours=2)
assert not authenticator.is_authenticated()
@pytest.mark.asyncio
async def test_make_authenticated_request(authenticator, mock_session, mock_response):
"""Test making an authenticated request"""
mock_session.request.return_value = mock_response
test_url = "https://bstock.com/amazon/test"
response = await authenticator.make_authenticated_request(test_url)
assert mock_session.request.called
call_args = mock_session.request.call_args
assert call_args[0][0] == "GET"
assert call_args[0][1] == test_url
@pytest.mark.asyncio
async def test_context_manager(mock_session, mock_response, mock_login_response):
"""Test async context manager functionality"""
mock_session.get.return_value = mock_response
mock_session.post.return_value = mock_login_response
with patch('aiohttp.ClientSession', return_value=mock_session):
async with BStockAuthenticator(TEST_EMAIL, TEST_PASSWORD) as auth:
assert auth.session is not None
assert isinstance(auth.session, AsyncMock)
assert auth.is_authenticated()
